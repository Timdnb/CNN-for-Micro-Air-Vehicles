{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possible -> normalize dataset (subtract mean and divide by std)\n",
    "- add batch / group norm to CNN\n",
    "- learning rate scheduler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import convert_image_dtype\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "# import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_layers = 3                # not implemented yet\n",
    "# input_size = (1, 130, 60)      # not implemented yet\n",
    "# output_channel = (20, 5, 8)\n",
    "# kernel_size = (7, 5, 3)\n",
    "# padding = (3, 2, 5)\n",
    "# stride = (2, 3, 4)\n",
    "# outputs = 3\n",
    "\n",
    "# def fc_neurons(n_layers, input_size, output_channel, kernel_size, padding, stride):\n",
    "#      for i in range(n_layers):\n",
    "#           print(input_size, i)\n",
    "#           input_size = [output_channel[i], int((input_size[1]+2*padding[i]-(kernel_size[i]-1))/stride[i]), int((input_size[2]+2*padding[i]-(kernel_size[i]-1))/stride[i])]\n",
    "#           print(input_size)\n",
    "#           input_size = [output_channel[i], int(input_size[1]/2), int(input_size[2]/2)]\n",
    "#           print(input_size)\n",
    "#      neurons = input_size[0] * input_size[1] * input_size[2]\n",
    "#      return neurons\n",
    "\n",
    "# print(fc_neurons(n_layers, input_size, output_channel, kernel_size, padding, stride)) # function doesnt work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture\n",
    "n_layers = 3                # not implemented yet\n",
    "input_size = (1, 130, 60)      # not implemented yet\n",
    "output_channel = (64, 16, 16)\n",
    "kernel_size = (3, 3, 3)\n",
    "padding = (1, 1, 1)\n",
    "stride = (1, 1, 1)\n",
    "outputs = 3\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 20\n",
    "label_smoothing = 0.0\n",
    "learning_rate = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792\n"
     ]
    }
   ],
   "source": [
    "def fc_neurons(n_layers, input_size, output_channel, kernel_size, padding, stride):\n",
    "     for i in range(n_layers):\n",
    "          input_size = [output_channel[i], int((input_size[1]+2*padding[i]-(kernel_size[i]-1))/stride[i]), int((input_size[2]+2*padding[i]-(kernel_size[i]-1))/stride[i])]\n",
    "          input_size = [output_channel[i], int(input_size[1]/2), int(input_size[2]/2)]\n",
    "     neurons = input_size[0] * input_size[1] * input_size[2]\n",
    "     return neurons\n",
    "\n",
    "print(fc_neurons(n_layers, input_size, output_channel, kernel_size, padding, stride)) # function doesnt work \n",
    "\n",
    "model_name = f\"test-CNN-e{num_epochs}-ls{label_smoothing}-lr{learning_rate}\".replace(\".\", \"_\")\n",
    "\n",
    "cfg={\"architecture\": \"CNN\",\n",
    "     \"epochs\": num_epochs,\n",
    "     \"learning_rate\": learning_rate,\n",
    "     \"label_smoothing\": label_smoothing,\n",
    "     \"input_size\": input_size,\n",
    "     \"output_channels\": output_channel,\n",
    "     \"kernel_sizes\": kernel_size,\n",
    "     \"padding\": padding,\n",
    "     \"stride\": stride,\n",
    "     \"fc_layer\": (48, outputs)\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset class\n",
    "class DroneImagesDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.annotations = np.genfromtxt(csv_file, delimiter=',', dtype=None, encoding=None, skip_header=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.annotations[index][0]\n",
    "        img_path = str(Path(img_path))\n",
    "        image = convert_image_dtype(read_image(img_path), torch.float)\n",
    "        left, forward, right = float(self.annotations[index][1]), float(self.annotations[index][2]), float(self.annotations[index][3])\n",
    "        y_label = torch.tensor([left, forward, right])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to try: bilinear, bicubic or nearest exact\n",
    "IMAGE_TRANSFORM = transforms.Compose([\n",
    "    transforms.CenterCrop((520, 120)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((26, 12), interpolation=transforms.InterpolationMode.NEAREST_EXACT),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "batch_size = 128\n",
    "dataset = DroneImagesDataset(csv_file='labeled_images.csv', transform=IMAGE_TRANSFORM)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "num_samples = len(dataset)\n",
    "num_val_samples = int(val_ratio * num_samples)\n",
    "num_test_samples = int(test_ratio * num_samples)\n",
    "num_train_samples = num_samples - num_val_samples - num_test_samples\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [num_train_samples, num_val_samples, num_test_samples]\n",
    ")\n",
    "\n",
    "# Create DataLoaders for the training, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, prefetch_factor=2, persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, prefetch_factor=2, persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, prefetch_factor=2, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# # show first 5 grayscale image\n",
    "# for i, (image, y_label) in enumerate(train_loader):\n",
    "#     if i < 5:\n",
    "#         plt.imshow(image[0][0], cmap='gray')\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "for i, image in enumerate(dataset):\n",
    "    # dtore transform\n",
    "    plt.imshow(image[0][0], cmap='gray')\n",
    "    transform = dataset.transform\n",
    "    dataset.transform = None\n",
    "    #plt.imshow(dataset[i][0][0], cmap='gray')\n",
    "    dataset.transform = transform\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningCNN(L.LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(cfg)\n",
    "        self.model = torch.nn.Sequential(\n",
    "            # Convolutional layer 1\n",
    "            torch.nn.Conv2d(self.hparams.input_size[0], self.hparams.output_channels[0], kernel_size=self.hparams.kernel_sizes[0], stride=self.hparams.stride[0], padding=self.hparams.padding[0]),\n",
    "            torch.nn.BatchNorm2d(self.hparams.output_channels[0]),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.025),\n",
    "            # Convolutional layer 2\n",
    "            torch.nn.Conv2d(self.hparams.output_channels[0], self.hparams.output_channels[1], kernel_size=self.hparams.kernel_sizes[1], stride=self.hparams.stride[1], padding=self.hparams.padding[1]),\n",
    "            torch.nn.BatchNorm2d(self.hparams.output_channels[1]),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.025),\n",
    "            # Convolutional layer 3\n",
    "            torch.nn.Conv2d(self.hparams.output_channels[1], self.hparams.output_channels[1], kernel_size=self.hparams.kernel_sizes[2], stride=self.hparams.stride[2], padding=self.hparams.padding[2]),\n",
    "            torch.nn.BatchNorm2d(self.hparams.output_channels[1]),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.025),\n",
    "            # Fully connected layer\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(self.hparams.fc_layer[0], self.hparams.fc_layer[1]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y, label_smoothing=self.hparams.label_smoothing)\n",
    "        loss.backward(retain_graph=True)\n",
    "        acc = torch.sum(torch.argmax(y_hat, dim=1) == torch.argmax(y, dim=1)) / len(y)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.log(\"train/acc\", acc)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        acc = torch.sum(torch.argmax(y_hat, dim=1) == torch.argmax(y, dim=1)) / len(y)\n",
    "        self.log(\"val/loss\", loss)\n",
    "        self.log(\"val/acc\", acc)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        acc = torch.sum(torch.argmax(y_hat, dim=1) == torch.argmax(y, dim=1)) / len(y)\n",
    "        self.log(\"test/loss\", loss)\n",
    "        self.log(\"test/acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "wand_blogger = WandbLogger(project=\"MAV-CNN-Project\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val/acc\", min_delta=0.005, patience=10, verbose=False, mode=\"max\")\n",
    "trainer = L.Trainer(max_epochs=cfg[\"epochs\"], logger=wand_blogger, default_root_dir=f\"lightning_logs/{model_name}\", callbacks=[early_stop_callback])\n",
    "model = LightningCNN(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtimdb\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240322_194908-0e6cjgmq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/timdb/MAV-CNN-Project/runs/0e6cjgmq' target=\"_blank\">gentle-rain-40</a></strong> to <a href='https://wandb.ai/timdb/MAV-CNN-Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/timdb/MAV-CNN-Project' target=\"_blank\">https://wandb.ai/timdb/MAV-CNN-Project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/timdb/MAV-CNN-Project/runs/0e6cjgmq' target=\"_blank\">https://wandb.ai/timdb/MAV-CNN-Project/runs/0e6cjgmq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 12.5 K\n",
      "-------------------------------------\n",
      "12.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.5 K    Total params\n",
      "0.050     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368e0179fcc44ef9b69e85ad9875c287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb31ccc51664f8989a99e22d02edbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6610c0fb204914a93abaadb220b82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abf28e828954673955a870d3af47166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89874e08cef432b8b191a96a52e4966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e792fa9da2f44e46a7244a005f0c5892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50560a5487ed4cd793f6cde707d8f776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5949f3ecc3f488d903d928b672d4a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17c3d3ab0154ec9990150dd266bef39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd5109837da4f158ba599da5aed373e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868c9db203f944d09c7e4522e935f80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7976a773560a4d338a725b2e8bf0629f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87145476423544039b64512e35fb23e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6306c8bbb4435eab977f2163f0cc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e90a949a9542ef90c3a8336b43ab7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983dc8467058431eb6aac57295d77d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29615566f1d4656985f0ed80419ebb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d56a67a302439c99dbc96bb8ec801d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6570f688db4a35a0316f6bf587b2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb45058c94c45c88aefaeb59bffff8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f3c1df15154dc1859d066174dd6d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b88b7aa4904e609b8552a639ff38d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "# Save model to onnx\n",
    "if True:\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 1, 130, 60)\n",
    "    dummy_input = torch.randn(1, 1, 26, 15)\n",
    "    torch.onnx.export(model, dummy_input, f\"{model_name}.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb62e1c476e7469ba7bfaeee30046170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5790795087814331     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9120391011238098     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5790795087814331    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9120391011238098    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Error while calling W&B API: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Error while calling W&B API: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "Thread SenderThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/apis/normalize.py\", line 41, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 2216, in upsert_run\n",
      "    response = self.gql(\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 341, in gql\n",
      "    ret = self._retry_gql(\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/lib/retry.py\", line 131, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 369, in execute\n",
      "    return self.client.execute(*args, **kwargs)  # type: ignore\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/lib/gql_request.py\", line 59, in execute\n",
      "    request.raise_for_status()\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://api.wandb.ai/graphql\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 93, in _run\n",
      "    self._debounce()\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 334, in _debounce\n",
      "    self._sm.debounce()\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 536, in debounce\n",
      "    self._maybe_update_config(always=final)\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 513, in _maybe_update_config\n",
      "    self._debounce_config()\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 542, in _debounce_config\n",
      "    self._api.upsert_run(\n",
      "  File \"/home/tim/.local/lib/python3.10/site-packages/wandb/apis/normalize.py\", line 51, in wrapper\n",
      "    raise CommError(message, error)\n",
      "wandb.errors.CommError: run timdb/MAV-CNN-Project/wcelzp78 was previously created and deleted; try a new run name (Error 409: Conflict)\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n"
     ]
    }
   ],
   "source": [
    "test = trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningCNN(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.025, inplace=False)\n",
       "    (5): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.025, inplace=False)\n",
       "    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): ReLU()\n",
       "    (14): Dropout(p=0.025, inplace=False)\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Linear(in_features=48, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3964, -1.6896,  2.6316]])\n",
      "tensor([[ 0.3494, -2.4129,  0.8073]])\n"
     ]
    }
   ],
   "source": [
    "img_1 = 'tmp/70251465.jpg'\n",
    "img_2 = 'tmp/84918044.jpg'\n",
    "\n",
    "img_1 = IMAGE_TRANSFORM(convert_image_dtype(read_image(img_1), torch.float))\n",
    "img_2 = IMAGE_TRANSFORM(convert_image_dtype(read_image(img_2), torch.float))\n",
    "\n",
    "img_1 = img_1.reshape(1, *img_1.shape)\n",
    "img_2 = img_2.reshape(1, *img_2.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    print(model(img_1))\n",
    "    print(model(img_2))\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
